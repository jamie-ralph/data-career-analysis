---
title: "Stack Overflow Developer Survey 2019: Exploring the characteristics of data scientists and data analysts"
output:
    github_document
---
<br>

```{r data-prep, include=F}

### Data preparation script ### 
library(tidyverse)
library(janitor)
library(patchwork)

# Read in the data

data_ft <- read_csv("survey_results_public.csv") %>%
    filter(Employment == "Employed full-time",
           ConvertedComp >= 3e4,
           ConvertedComp <= 3e5,
           Age >= 18,
           Country == "United States"
    )

# Identify managers and academics

managers <- data_ft %>%
    filter(str_detect(DevType, "Engineering manager|Product manager|Senior executive/VP"))

academics <- data_ft %>%
    filter(str_detect(DevType, "Academic researcher|Scientist|Educator"))

# Filter to data scientists and data analysts only

data_jobs <- data_ft %>% 
    anti_join(managers) %>%
    anti_join(academics) %>%
    mutate(DevType = str_split(DevType, pattern = ";")) %>%
    unnest(DevType) %>%
    mutate(DevType = case_when(
        str_detect(str_to_lower(DevType), "data scientist") ~ "Data scientist",
        str_detect(str_to_lower(DevType), "data or business") ~ "Data analyst",
        TRUE ~ "Other") ) %>%
    filter(DevType != "Other")



# Filter df to people who selected both job types, then anti join to get
# respondents who selected one job type

both_jobs <- data_jobs %>%
    group_by(Respondent) %>%
    summarise(Count = n()) %>%
    filter(Count > 1) %>%
    select(-Count)

df <- data_jobs %>%
    anti_join(both_jobs)


# Some additional data wrangling to make working with categorical data easier

df <- df %>%
    mutate(
        Gender = case_when(
        str_detect(Gender, "Non-binary") ~ 
            "Non-binary, genderqueer, or gender non-conforming",
        is.na(Gender) ~ "Not available",
        TRUE ~ Gender),
        MainBranch = case_when(
            str_detect("I am a developer by profession", 
                       MainBranch) ~ "Professional developer",
            TRUE ~ "Not professional developer"
        ),
        OrgSize = fct_collapse(OrgSize,
                               `Between 2 and 99` = c("2-9 employees", "10 to 19 employees", "20 to 99 employees"),
                               `Between 100 and 999` = c("100 to 499 employees", "500 to 999 employees"),
                               `Between 1,000 and 4,999` = "1,000 to 4,999 employees",
                               `5,000 or more` = c("5,000 to 9,999 employees", "10,000 or more employees")
        ),
        OpenSourcer = fct_collapse(OpenSourcer,
                                   Never = "Never",
                                   Sometimes = "Less than once per year",
                                   Often = c(
                                       "Less than once a month but more than once per year",
                                       "Once a month or more often"
                                   )
            )
    )

df <- df %>%
    mutate(
    EdLevel = case_when(
        EdLevel %in% c(
            "I never completed any formal education",
            "Primary/elementary school",
            "Secondary school (e.g. American high school, German Realschule or Gymnasium, etc.)",
            "Some college/university study without earning a degree",
            "Associate degree"
        ) ~ "Less than bachelors",
        EdLevel == "Bachelor’s degree (BA, BS, B.Eng., etc.)" ~ "Bachelors degree",
        EdLevel %in% c(
            "Other doctoral degree (Ph.D, Ed.D., etc.)",
            "Master’s degree (MA, MS, M.Eng., MBA, etc.)",
            "Professional degree (JD, MD, etc.)"
        ) ~ "Graduate degree",
        TRUE ~ EdLevel
    )
    )


```

```{r code-prep, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)

devtype_scale_colour <- function() {
    scale_colour_manual(breaks = c("Data analyst", "Data scientist"),
                        values = c("#94D0FF", "#AD8CFF"))
}

devtype_scale_fill <- function() {
    scale_fill_manual(breaks = c("Data analyst", "Data scientist"),
                        values = c("#94D0FF", "#AD8CFF"))
}

med_ds <- scales::dollar(
  median(df[df$DevType == "Data scientist",]$ConvertedComp)
)

med_da <- scales::dollar(
  median(df[df$DevType == "Data analyst",]$ConvertedComp)
)

Mode <- function(x) {
  ux <- unique(x)
  ux[which.max(tabulate(match(x, ux)))]
}


```


In this project I'll be exploring survey responses from data scientists and data analysts in [Stack Overflow's 2019 Developer Survey](https://insights.stackoverflow.com/survey/2019#overview). I'll be using the survey responses to build a statistical model of industry salaries. 

This project reuses code from Julia Silge's brilliant analysis of [gender and salary in the tech industry](https://juliasilge.com/blog/salary-gender/) - I highly recommend you check it out!



#### Preparing the data

To fit a more accurate model of salary the data were filtered to:

* full-time workers 

* residing in the United States

* salaries between between \$30,000 and \$300,000

* individual contributors working in industry only (i.e. removing upper management and academics)

This made the data more consistent for visualising and modelling. [This analysis by Charles Modingwa](https://medium.com/@charlesmodingwa/2019-stack-overflow-survey-analysis-c8dac1617d40) showed that data scientist salaries differed across countries. Filtering only to the United States removes any unwanted effects of country and still leaves a good sample size. 

Respondents were labelled as data analysts if they identified as a "Data or business analyst" or a data scientist if identifying as "Data scientist or machine learning specialist". `r nrow(both_jobs)` respondents identified with both labels. These responses were removed to focus the analysis on the differences between the two groups. This left `r nrow(df)` responses, consisting of `r nrow(filter(df, DevType == "Data scientist"))` data scientists and `r nrow(filter(df, DevType == "Data analyst"))` data analysts. 


### Part 1 - Exploring the data

Before building a model, I'll build some exploratory plots of salary and other
variables in the survey. I chose variables based on analyses that have already looked at modelling salaries in this dataset, combined with some additional variables I was interested in. 

#### What do data scientists and data analysts earn? 

If we take a look at salaries overall, the median salary is higher for data scientists (`r med_ds`) than for data analysts (`r med_da`). Salaries for both groups are positively skewed due to small number of respondents earning around $150,000 or more. For modelling purposes the salaries will be log10 transformed to make them normally distributed. 
```{r fig.width=12}
salary_boxplot <- df %>%
    ggplot(aes(DevType, ConvertedComp,  colour = DevType)) +
    geom_boxplot(outlier.colour = NA, width = 0.5) +
    theme_minimal(base_size = 12) +
    geom_jitter(alpha = 0.3, width = 0.1) +
    scale_y_continuous(labels = scales::dollar_format()) +
    labs(
        x = "",
        y = "Salary (USD)"
    ) +
    theme(
        legend.position = "none"
    ) +
    devtype_scale_colour()

salary_hist <- df %>%
  ggplot(aes(x = ConvertedComp, y = DevType))  +
  ggridges::geom_density_ridges(aes(fill = DevType)) +
  theme_minimal() +
  scale_x_continuous(
    labels = scales::dollar_format()
  ) +
  labs(
    x = "Salary (USD)",
    y = ""
  ) +
  devtype_scale_fill() +
  theme(
    legend.position = "none"
  ) +
  ggtitle("Original salary")

salary_hist_log <- df %>%
  ggplot(aes(x = log10(ConvertedComp), y = DevType))  +
  ggridges::geom_density_ridges(aes(fill = DevType)) +
  theme_minimal() +
  scale_x_continuous(
    labels = scales::dollar_format()
  ) +
  labs(
    x = "Log10 salary (USD)",
    y = ""
  ) +
  devtype_scale_fill() +
  theme(
    legend.position = "none"
  ) +
  ggtitle("Salary with log10 transform")



salary_boxplot / (salary_hist + salary_hist_log)
```

<br>

#### Does salary differ by gender identity?

The data shows that the majority of respondents identified as men. Data scientists had higher median salaries than data analysts across the gender groups. It's possible that women are under-represented in this sample, an issue that has been identified for the survey across all developer roles. This means that, despite the boxplot indicating only a small gender difference between men and women, this result may not reflect the real world. `r nrow(filter(df, Trans == "Yes"))` respondents in this sample identified as trans. 
 

```{r fig.width=12}
df %>%
    filter(!is.na(Gender), Gender != "Not available") %>%
    ggplot(aes(x = DevType, y = ConvertedComp, colour = DevType)) + 
    geom_boxplot(outlier.colour = NA) + 
    facet_wrap(~factor(Gender, levels = c("Man", 
                                          "Woman", 
                                          "Non-binary, genderqueer, or gender non-conforming"))) +
    theme_minimal(base_size = 12) +
    geom_jitter(alpha = 0.3, width = 0.2) +
    scale_y_continuous(labels = scales::dollar_format()) +
    labs(
        x = "",
        y = "Salary (USD)"
    ) +
    theme(
        legend.position = "none"
    ) +
    devtype_scale_colour()

```

#### Do salaries increase with age, or is it about experience?

We would expect that salaries will increase with age and years of professional experience as respondents move into more senior roles. The ridge plots below show that age and years of professional coding are distributed non-normally with a positive skew. Typically we can log-transform skewed variables to make them more suitable for fitting statistical models. 

```{r, fig.width=12}
hist_age <- df %>%
    ggplot(aes(x = Age, y = DevType, fill = DevType, colour = DevType)) +
    ggridges::geom_density_ridges() +
    theme_minimal(base_size = 12) +
    devtype_scale_fill() +
    devtype_scale_colour() +
    labs(
        y = "Number of respondents"
    ) +
    theme(
        legend.position = "none"
    )

hist_exp <-  df %>%
  mutate(
    YearsCodePro = case_when(
      YearsCodePro == "Less than 1 year" ~ "0",
      TRUE ~ YearsCodePro
    ),
    YearsCodePro = as.numeric(YearsCodePro)
  ) %>%
  ggplot(aes(x = YearsCodePro, y = DevType, fill = DevType, colour = DevType)) +
  ggridges::geom_density_ridges()  +
    theme_minimal(base_size = 12) +
    devtype_scale_fill() +
    devtype_scale_colour() +
    labs(
        x = "Years of professional coding",
        y = "Number of respondents"
    ) +
    theme(
        legend.position = "none"
    )



scatter_age <- df %>%
    filter(Age >= 18) %>%
    ggplot(aes(x = log10(Age), y = log10(ConvertedComp), colour = DevType)) +
    theme_minimal(base_size = 12) +
    guides(colour = guide_legend(override.aes = list(size = 5))) +
    geom_point() +
    geom_smooth(method = "lm", se = FALSE, size = 1.5) +
    labs(
        x = "Log10 Age",
        y = "Log10 Salary (USD)"
    ) +
    scale_y_continuous(labels = scales::dollar_format()) +
    devtype_scale_colour() 

scatter_exp <- df %>%
  mutate(
    YearsCodePro = case_when(
      YearsCodePro == "Less than 1 year" ~ "0",
      TRUE ~ YearsCodePro
    ),
    YearsCodePro = as.numeric(YearsCodePro)
  ) %>%
  ggplot(aes(x = log10(YearsCodePro), y = log10(ConvertedComp), colour = DevType)) +
  geom_point() +
  theme_minimal(base_size = 12) +
  guides(colour = guide_legend(override.aes = list(size = 5))) +
  geom_smooth(method = "lm", se = FALSE, size = 1.5) +
    labs(
        x = "Log10 Years of professional coding",
        y = "Log10 Salary (USD)"
    ) +
    scale_y_continuous(labels = scales::dollar_format()) +
    devtype_scale_colour() 
  
  

(hist_age + hist_exp) / (scatter_age + scatter_exp)
```
<br>

The scatter plot on the right shows that log transforming years of professional coding doesn't quite work for the lower end of the scale. The transformed age plot on the left looks much cleaner and shows a positive relationship between log age and log salary. 


#### Does education affect future salaries?

Median salary was higher for data scientists at each aggregated qualification level. Overall there was a stronger positive effect of education on median earnings in the data scientist group compared to the data analyst group. Breaking down salaries by undergrad major and developer type shows that data scientists who studied maths or statistics had the highest median salary while data analysts with a social sciences background had the lowest median salary. 


```{r}
levels = c("Less than bachelors", "Bachelors degree", "Graduate degree")

ed_boxplot <- df %>%
  mutate(
    EdLevel = case_when(
                       EdLevel %in% c(
                                   "I never completed any formal education",
                                   "Primary/elementary school",
                                   "Secondary school (e.g. American high school, German Realschule or Gymnasium, etc.)",
                                   "Some college/university study without earning a degree",
                                   "Associate degree"
                               ) ~ "Less than bachelors",
                               EdLevel == "Bachelor’s degree (BA, BS, B.Eng., etc.)" ~ "Bachelors degree",
                               EdLevel %in% c(
                                   "Other doctoral degree (Ph.D, Ed.D., etc.)",
                                   "Master’s degree (MA, MS, M.Eng., MBA, etc.)",
                                   "Professional degree (JD, MD, etc.)"
                               ) ~ "Graduate degree",
                       TRUE ~ EdLevel
        )
  ) %>%
    filter(!is.na(EdLevel)) %>%
    ggplot(aes(x = factor(EdLevel, levels = levels), y = ConvertedComp, colour = DevType)) +
    geom_boxplot() +
    scale_y_continuous(labels = scales::dollar_format()) +
    theme_minimal(base_size = 12) +
    scale_colour_manual(breaks = c("Data analyst", "Data scientist"),
                        values = c("#94D0FF", "#AD8CFF")) +
    labs(
        x = "Highest qualification",
        y = "Salary (USD)"
    )

ed_table <- df %>%
    filter(!is.na(UndergradMajor)) %>%
    group_by(UndergradMajor, DevType) %>%
    summarise(`Sample size` = n(), 
              `Median salary` = median(ConvertedComp)) %>%
    filter(`Sample size` >= 30) %>%
    arrange(-`Median salary`) %>%
    mutate(
        `Median salary` = scales::dollar(`Median salary`)
    ) %>%
    kableExtra::kable()

ed_boxplot 

ed_table

```

#### Do employment variables affect salary?

There is an interesting interaction here: data analysts who are primarily professional developers have a higher median log of salary than those aren't, but this effect is absent in the data scientist group. There was a very small upward trend of salary ranges as organisation size increased. 
<br>

```{r}
prof_boxplot <- df %>%
    ggplot(aes(x = MainBranch, y = log10(ConvertedComp), colour = DevType)) +
    geom_boxplot() +
    scale_y_continuous(
        labels = scales::dollar_format()
    ) +
    theme_minimal() +
  labs(
    x = "",
    y = "Log10 Salary (USD)"
  ) +
  theme(
    legend.position = "none"
  ) +
    devtype_scale_colour() 

org_boxplot <- df %>%
    filter(!is.na(OrgSize)) %>%
    mutate(
        OrgSize = factor(OrgSize,
                         levels = c(
        "Between 2 and 99",
        "Between 100 and 999",
        "Between 1,000 and 4,999",
        "5,000 or more")
        )
    ) %>%
    ggplot(aes(x = OrgSize, y = log10(ConvertedComp), colour = DevType)) +
    geom_boxplot() +
    scale_y_continuous(
        labels = scales::dollar_format()
    ) +
    labs(
      x = "Organisation size (employees)",
      y = "Log10 Salary (USD)"
    ) +
    theme_minimal() +
    devtype_scale_colour() +
    coord_flip()

prof_boxplot / org_boxplot
    
```

Most respondents in the sample worked `r Mode(df$WorkWeekHrs)` hours a week. The scatterplots here suggest that higher working hours per week may result in higher log10 salary, but fitting a linear relationship would be confounded by the large number of respondents on the 40 hours line. 

``` {r fig.width = 12}
df %>%
  filter(!is.na(WorkWeekHrs),
         WorkWeekHrs < 100) %>%
  ggplot(aes(x = WorkWeekHrs, y = log10(ConvertedComp), colour = DevType)) +
  geom_point() +
  scale_y_continuous(
    labels = scales::dollar_format()
  ) +
  theme_minimal() +
  theme(
    legend.position = "none"
  ) +
  labs(
    x = "Hours worked per week",
    y = "Log10 Salary (USD)"
  ) +
  devtype_scale_colour() +
  facet_wrap(~DevType) 
  
```

#### Does knowing more programming languages relate to salary?


The number of programming languages used had a small positive effect on median earnings in the data analyst group, however the effect was somewhat negative in the data scientist group. 


```{r fig.width=12}
langs_used <- df %>%
    mutate(
        LanguageWorkedWith = str_split(LanguageWorkedWith, pattern = ";")
    ) %>%
    unnest(LanguageWorkedWith) %>%
    group_by(Respondent) %>%
    summarise(languages_used = n()) %>%
    mutate(
        languages_used = case_when(
            languages_used > 10 ~ 10,
            TRUE ~ as.numeric(languages_used)
        )
    )

df %>%
    inner_join(langs_used, by = "Respondent") %>%
    mutate(
      log_salary = log10(ConvertedComp)
    ) %>%
    group_by(DevType, languages_used) %>%
    summarise(med_log_salary = median(log_salary)) %>%
    ggplot(aes(x = languages_used, y = med_log_salary)) +
    geom_line(alpha = 0.5, size = 2, aes(colour = DevType)) +
    theme_minimal(base_size = 12) +
    labs(
        x = "Number of programming languages used \n (capped at 10)",
        y = "Median log10 salary (USD)"
    ) +
    scale_y_continuous(
        labels = scales::dollar_format()
    ) +
    scale_x_continuous(
        breaks = 1:10,
        minor_breaks = NULL
    ) +
    devtype_scale_colour() 
```



#### Do open source contributors earn more?

Finally, the plot below shows that open source contributions have a small positive effect on median salaries in the data scientist group but not in the data analyst group. 

```{r}
df %>%
      ggplot(aes(x = OpenSourcer, y = log10(ConvertedComp), colour = DevType)) + 
      geom_boxplot() +
      labs(
            y = "Log10 Salary (USD)",
            x = ""
        ) +
    theme_minimal() +
    facet_wrap(~DevType) +
    devtype_scale_colour()
```

### Part 2 - Building a model

#### Multiple regression output

It's clear that salaries are highly variable whichever way we look at the data. The exploratory data analysis we've done so far suggests that some variables could explain some of the variation in salaries, and this is where modelling comes in! Here I'll try a multiple regression to model salary on **developer type**, **professional vs. non-professional developer**, **log transformed age**, **education level**, and **open source contributions**, including some interaction terms based on the exploratory plots. 
```{r}
library(moderndive)

# Fit a simple linear regression

model_data <- df %>%
    select(ConvertedComp, Age, DevType, EdLevel, OrgSize, OpenSourcer, MainBranch) %>%
    mutate(log_salary = log10(ConvertedComp),
           log_age = log10(Age)) %>%
    select(-ConvertedComp, -Age)


simple_lm <- lm(log_salary ~ log_age + DevType * OpenSourcer + DevType * EdLevel + DevType * MainBranch, data = model_data)

```

```{r}

simple_lm %>%
  get_regression_summaries() %>%
  kableExtra::kable()

simple_lm %>%
  get_regression_table() %>%
  kableExtra::kable()
```

Given the variability in the data, an adjusted R-squared of 0.31 isn't bad! The model has accounted for about 31% of the variance in log of salary. The one continuous variable in the model (log of age) has a significant positive effect on average log of salary. There is also a significant positive effect of being a data scientist on the average log of salary. There is a significant negative effect of not having at least a bachelor's degree for data analysts but not for data scientists. Being a professional developer significantly increases log of salary for data analysts but does not have an effect on data scientist salaries. Open source contributions didn't have an effect in either group. 

#### Everybody's favourite - checking assumptions!

It's important to check that the regression has met the underlying assumptions before drawing conclusions:

* **Linearity** of relationships between independent and dependent variables - we can be satisfied this assumption is met by looking at the EDA plots and by checking that there is no pattern when plotting fitted values against residuals
* **Independence** of residuals - responses come from different individuals, so we meet this criterion
* **Normality of residuals** - the normal Q-Q below shows our residuals are distributed normally across log of salary
* **Homogeneity of variance** - we can check this assumption using a scale-location plot and checking there is no linear pattern, which is what we find here

We can also check the Residuals vs Leverage plot to make sure outliers are not significantly affecting the regression coefficients. The plot here doesn't show any observations outside of Cook's distance, so we can assume that outliers aren't having a large impact on the model. 

```{r fig.width=12}
par(mfrow = c(1, 2))
plot(simple_lm, which = 1:2)

```

```{r fig.width=12}

par(mfrow = c(1, 2))
plot(simple_lm, which = c(3, 5))
```

### Conclusion

This project was a lot of fun to work through! There are clearly many factors that can influence data scientist and data analyst salaries that weren't captured here, but we did find a positive effect of age and some interesting interactions between developer type, education level, and whether or not a person is a professional developer. There are some further analyses we could do to improve on the multiple regression model we built here, for example a linear mixed effects model including organisation size and undergraduate major as random effects (this type of model is covered in Julia Silge's post). 

**Thanks for reading :)**
